{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Unsupervised Learning Bootcamp Graded Hands-on Exercise.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vjqkJbJBmGA"
      },
      "source": [
        "### **Overview**\n",
        "\n",
        "Throughout this assignment, you will be performing specific well-defined tasks thatâ€™ll strengthen your concepts in Unsupervised Learning. We will be using the facebook live sellers dataset for Task 1 & 2 of the assignment and here is a brief context about the same - The data is about live selling feature on the Facebook platform. Each record consists of information about the time live information of sale is posted to Facebook and engagements in the data. The engagements are regular Facebook interactions such as share and emotion rection.\n",
        "\n",
        "As part of the assignment, you will have to accomplish the below tasks.\n",
        "\n",
        "\n",
        "**Author:** Chintoo Kumar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5U0zsQcBW2j"
      },
      "source": [
        "###**Dataset**\n",
        "\n",
        "Dataset Link: https://archive.ics.uci.edu/ml/machine-learning-databases/00488/Live_20210128.csv\n",
        "\n",
        "**About the dataset:**\n",
        "\n",
        "The Facebook Live Sellers in Thailand is a dataset curated in UCI Machine Learning Datasets. It data contains 7050 observations and twelve attributes. In this assignment, the preprocessed dataset contains 7050 instances and 10 attributes. The details of the attributes are as follows:\n",
        "\n",
        "* status_type: The type of shared status\n",
        "* num_reactions: Number of glimpses over a shared status by viewers\n",
        "* num_comments: Number of comments on that particular shared status\n",
        "* num_shares: Toal number of shares by peers\n",
        "* num_likes: Number of likes on the post\n",
        "* num_loves: Number of love emojis of that shared post\n",
        "* num_wows: Number of wow emojis on that post\n",
        "* num_hahas: Number of haha emojis on that post\n",
        "* num_sads: Number of sad emojis on that post\n",
        "* num_angrys: Number of angry emojis on that post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt260k7VBW2k"
      },
      "source": [
        "### **Task 1: Data loading and Data Analysis**\n",
        "\n",
        "* Load the data file into a dataframe object : df\n",
        "* Display the first 5 observation of the dataset\n",
        "* Display a concise summary of the provided data and list out 2 observations/inferences that you observe from the result. You can use the info() method for this.\n",
        "* Perform EDA viz. Is there any missing values in each column of the provided dataset\n",
        "* Display all the unique status_type of the dataframe\n",
        "* Convert categorical variable, i.e., status_type into numerical representation using a label encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG3wQpWzDjp1"
      },
      "source": [
        "###**Task 2: Feature Scaling**\n",
        "\n",
        "\n",
        "*   Perform normalization to scale numerical data prior to modeling. You may use Min-max scaling technique\n",
        "*   Use Elbow method to determine the number of cluster to be formed\n",
        "*   Verify optimal number of clusers on the basis of silhouette scores\n",
        "*   Assigning cluster label to each instance of the dataframe\n",
        "*   Validating obtained clusters using external cluster validation approaches like rand_score and adjusted_rand_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P9m4XFNF82H"
      },
      "source": [
        "###**Task 3: Perform PCA on Fruit Dataset**\n",
        "\n",
        "Fruit Dataset Link: https://raw.githubusercontent.com/dphi-official/Datasets/master/fruit_data.csv\n",
        "\n",
        "* Use PCA to find the first two principal components of the fruit dataset\n",
        "* Scale the value. Each feature should be centered (zero mean) and with unit variance\n",
        "* Analysis - perform PCA with 4 components and print their explained variance_ratio\n",
        "\n"
      ]
    }
  ]
}